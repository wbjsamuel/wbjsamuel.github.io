---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "<https://cdn.jsdelivr.net/gh/>" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "<https://raw.githubusercontent.com/>" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Hi, I am an undergraduate student from the first session of [Guozhi Class](http://www.qingyuan.sjtu.edu.cn/c/Introductiongzb) (held by [Prof.Xiaoou Tang](https://www.ie.cuhk.edu.hk/faculty/Tang-Xiaoou-Sean/) and [Prof.Cewu Lu](https://www.mvig.org/)), Shanghai Jiao Tong University and major in **Artificial Intelligence**. Currently, I work as a intern researcher at both [Agibot](https://www.agibot.com) and PKU-Agibot Lab(supervised by Prof. [Hao Dong](https://zsdonghao.github.io)). Previously, I worked as a research intern at [OpenDriveLab](https://opendrivelab.com)(supervised by Prof. [Hongyang Li](https://lihongyang.info)) and research undergrad. at [ReThinkLab](https://thinklab.sjtu.edu.cn), supervised by Prof. [Junchi Yan](https://thinklab.sjtu.edu.cn).

My research interest includes **Robot Learning, Embodied AI, autonomous driving and computer vision**. <a href="https://scholar.google.com/citations?user=_LeSlzUAAAAJ"><img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fwbjsamuel%2Fwbjsamuel.github.io%40google-scholar-stats%2Fgs_data_shieldsio.json&amp;logo=Google%20Scholar&amp;labelColor=f6f6f6&amp;color=9cf&amp;style=flat&amp;label=citations"></a>

Recently, I have co-led a project related to human-oriented representation learning for robot manipulation, which has been accepted by <span style="color:#090;background-color:#DAF7A6"><b>RSS 2024</b></span>ü•≥. And now I am leading a project on VLA framework like RT-X, Octo, and etc.ü¶æ In my spare time, I enjoy playing tennis, travelling and drilling my skills in both photography and cinematography and I am also a big fan of jazz and classical music! If you want to know more about me beyond my research, please visit [here](https://bysamuel.notion.site).

- My latest resume is available here: [CV](https://wbjsamuel.github.io/files/Bangjun_Resume_Jun15.pdf) [Updated on 15 June, 2024].
- I am seeking 2024 summer research position and actively applying for 2025 Fall Ph.D in the US. If you are interested in my research, please feel free to contact me via [email](mailto:wbjsamuel+001@gmail.com)

# üî• News
- 2024.07: &nbsp; Attend RSS 2024 on-site and present our work on
  <grow>
    <b>
      <div class="tooltip">robot manipulation. 
        <span class="tooltiptext">
          <img src="images/RSS.png" alt="sym"><br>
          <div style="font-size: 12px; font-weight: normal">
          July 2024, at TU Delft.
          </div>
        </span>
      </div>
    </b>
  </grow> 
- 2024.05: &nbsp; Serve as a reviewer for  <span style="color:#00aeff;background-color:#e6f7ff"><b>NeurIPS 2024</b></span> and <span style="color:#00aeff;background-color:#e6f7ff"><b>ACMMM 2024</b></span>
- 2024.05: &nbsp; One paper(MPI) on robot manipulation has been accepted by <span style="color:#090;background-color:#DAF7A6"><b>RSS 2024</b></span>.
- 2024.03: &nbsp; Join [PKU-Agibot Lab](https://zsdonghao.github.io/#lab) supervised by Prof.[Hao Dong](https://zsdonghao.github.io).
<!-- - 2024.02: &nbsp; One paper on robot manipulation has been submitted to <span style="color:#090;background-color:#DAF7A6"><b>RSS 2024</b></span>. -->
- 2024.01: &nbsp; One paper(LaneSegNet) is accepted by  <span style="color:#00aeff;background-color:#e6f7ff"><b>ICLR 2024</b></span>.
- 2023.11: &nbsp; Going to serve as a reviewer for  <span style="color:#00aeff;background-color:#e6f7ff"><b>CVPR 2024</b></span>
- 2023.09: &nbsp; One paper(OpenLane-V2) is accepted by  <span style="color:#00aeff;background-color:#e6f7ff"><b>NeurIPS 2023</b></span>.
- 2023.07: &nbsp; Serve as the session secretary in [RACV 2023](https://mp.weixin.qq.com/s/xq5vVxIL27NLLQX9oFgv1w).
- 2023.03: &nbsp; Become a member of [OpenDriveLab](https://opendrivelab.com).
<details>
  <summary>Earlier News</summary>
  <ul>
    <li>2023.02: &nbsp; Participate in MCM/ICM 2023, collaborating with Wenye Yu and Yunlin He.</li>
    <li>2022.11: &nbsp; Become a member of  <a href="https://thinklab.sjtu.edu.cn">ReThinkLab</a>.</li>
    <li>2022.08: &nbsp; Join Prof. <a href="https://ynysjtu.github.io">Nanyang Ye</a>‚Äôs Laboratory in JHC, Shanghai Jiao Tong University.</li>
    <li>2021.12: &nbsp; Enrolled in <a href="http://www.qingyuan.sjtu.edu.cn/c/Introductiongzb">Guozhi Class</a>.</li>
  </ul>
</details>
# üíª Experience
<div class='paper-box-right'><div class='paper-box-image'><div><a href="https://www.agibot.com"><img src='images/agibot.png' alt="sym" width="100px" style="padding: 10px;"></a></div></div>
<div class='paper-box-text' markdown="1">
## AGIBOT

*2024.05 - (present)*, Supervisor: Dr. [Maoqing Yao](https://www.linkedin.com/in/maoqing-yao-565a5924?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=ios_app).
- **Humanoid Bimanual Manipulation**

</div>
</div>

<div class='paper-box-right'><div class='paper-box-image'><div><a href="https://www.pku.edu.cn"><img src='images/pku.png' alt="sym" width="100px" style="padding: 10px;"></a></div></div>
<div class='paper-box-text' markdown="1">
## PKU-Agibot Lab, Peking University(PKU)

*2024.03 - (present)*, Supervisor: Prof. [Hao Dong](https://zsdonghao.github.io).
- **Robotics, Robot Learning**

</div>
</div>

<div class='paper-box-right'><div class='paper-box-image'><div><a href="https://opendrivelab.com"><img src='images/hku.jpg' alt="sym" width="100px" style="padding: 10px;"></a></div></div>
<div class='paper-box-text' markdown="1">
## OpenDriveLab, The University of Hong Kong(HKU)

*2023.03 - 2024.06*, Supervisor: Prof. [Hongyang Li](https://lihongyang.info).
- **Robotics, Robot Learning**
- **Structural Understanding for Driving Scenes**

</div>
</div>

<div class='paper-box-right'><div class='paper-box-image'><div><a href="https://thinklab.sjtu.edu.cn"><img src='images/sjtu_logo.png' alt="sym" width="100px" style="padding: 10px;"></a></div></div>
<div class='paper-box-text' markdown="1">
## ReThinkLab, Shanghai Jiao Tong University(SJTU)

*2022.11 - 2023.05*, Supervisor: Prof. [Junchi Yan](https://thinklab.sjtu.edu.cn).
- **Image Retrieval, Image Matching**

</div>
</div>

<!-- <div class='paper-box-right'><div class='paper-box-image'><div><a href="https://ynysjtu.github.io/"><img src='images/sjtu_logo.png' alt="sym" width="100px" style="padding: 10px;"></a></div></div>
<div class='paper-box-text' markdown="1">
## Nanyang Ye‚Äôs lab, JHC, Shanghai Jiao Tong University

*2022.6 - 2022.11*, Supervisor: Prof. [Nanyang Ye](https://ynysjtu.github.io)
- **Causal Inference, OoD learning, OoD HDR Video Compression**
</div>
</div> -->

# üìù Publications
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">RSS 2024</div><img src='images/mpi.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1" style="font-family:  Noto Serif, Georgia, serif; font-size: 14px;">
[**Learning Manipulation by Predicting Interaction**](https://arxiv.org/abs/2406.00439)**(Co-first Author)**

Jia Zeng$^\ast$, Qingwen Bu$^\ast$, **Bangjun Wang$^\ast$**, Wenke Xia$^\ast$, Li Chen, Hao Dong, H.Song, D.Wang, D.Hu, P.Luo, H.Cui, B.Zhao, X.Li, Y.Qiao, Hongyang Li 

[**Github**](https://github.com/OpenDriveLab/MPI)<strong><span class='show_paper_citations' data='_LeSlzUAAAAJ:u-x6o8ySG0sC'></span></strong>

- *We propose a general pre-training pipeline that learns Manipulation by Predicting the Interaction (MPI).* <a href="https://github.com/OpenDriveLab/MPI"><img src="https://img.shields.io/github/stars/OpenDriveLab/MPI?style=social" alt="GitHub" style="opacity: .8"></a>
- [Project Page](https://opendrivelab.com/MPI/) \| [arXiv](https://arxiv.org/abs/2406.00439)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR 2024</div><img src='images/lane_segment.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1" style="font-family:  Noto Serif, Georgia, serif; font-size: 14px;">
[**LaneSegNet: Map Learning with Lane Segment Perception for Autonomous Driving**](https://arxiv.org/abs/2312.16108)**(Co-first Author)**

Tianyu Li$^\ast$, Peijin Jia$^\ast$, **Bangjun Wang$^\ast$**, Li Chen, Kun Jiang, Junchi Yan, Hongyang Li

[**Github**](https://github.com/OpenDriveLab/LaneSegNet)<strong><span class='show_paper_citations' data='_LeSlzUAAAAJ:u-x6o8ySG0sC'></span></strong>

- *We advocate Lane Segment as a map learning paradigm that seamlessly incorporates both map üõ£Ô∏è geometry and üï∏Ô∏è topology information.* <a href="https://github.com/OpenDriveLab/LaneSegNet"><img src="https://img.shields.io/github/stars/OpenDriveLab/LaneSegNet?style=social" alt="GitHub" style="opacity: .8"></a>
- [Track Mapless Driving, Autonomous Grand Challenge, CVPR 2024](https://opendrivelab.com/challenge2024/#mapless_driving)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeuraIPS 2023</div><img src='images/olv2.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1" style="font-family:  Noto Serif, Georgia, serif; font-size: 14px;">
[**OpenLane-V2: A Topology Reasoning Benchmark for Scene Understanding in Autonomous Driving**](https://openreview.net/pdf?id=OMOOO3ls6g)

Huijie Wang, Tianyu Li, Yang Li, Li Chen, Chonghao Sima, Zhenbo Liu, **Bangjun Wang**, Peijin Jia, Yuting Wang, Shengyin Jiang, Feng Wen, Hang Xu, Ping Luo, Junchi Yan, Wei Zhang, Hongyang Li

[**Project**](https://github.com/OpenDriveLab/OpenLane-V2) <strong><span class='show_paper_citations' data='_LeSlzUAAAAJ:u-x6o8ySG0sC'></span></strong>

- *The World's First Perception and Reasoning Benchmark for Scene Structure in Autonomous Driving.* <a href="https://github.com/OpenDriveLab/OpenLane-V2"><img src="https://img.shields.io/github/stars/OpenDriveLab/OpenLane-V2?style=social" alt="GitHub" style="opacity: .8"></a>
- [Track OpenLane Topology, AD Challenge 2023, CVPR 2023](https://opendrivelab.com/AD23Challenge.html#openlane_topology)
</div>
</div>

<!-- - [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020** -->

<!-- # üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->

# üìñ Educations

- *2021.09 - Present*, Undergraduate, Artificial Intelligence, Guozhi Class, SEIEE, Shanghai Jiao Tong University.
- **TOEFL iBT**: 106(R:29, L:28, S:22, W:27)(first time), **CET6**: 638(first time)

# üßëüèª‚Äçüíª Service
- Reviewer for <span style="color:#00aeff;background-color:#e6f7ff"><b>CVPR 2024</b></span>, <span style="color:#00aeff;background-color:#e6f7ff"><b>ACMMM 2024</b></span>, <span style="color:#00aeff;background-color:#e6f7ff"><b>NeurIPS 2024</b></span>
- Maintainer for [opendrivelab.com](https://opendrivelab.com) and [opendrivelab.sjtu.edu.cn](https://opendrivelab.sjtu.edu.cn)
- Administrator of Computing Cluster, Guozhi Class, SEIEE, Shanghai Jiao Tong University.
- Class monitor, Guozhi Class, SEIEE, Shanghai Jiao Tong University.

<!-- # üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

-  -->
  
